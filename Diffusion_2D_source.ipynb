{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa698dba",
   "metadata": {},
   "source": [
    "# Diffusion models\n",
    "\n",
    "Synthetid 2-D data\n",
    "\n",
    "2024-2-10\n",
    "\n",
    "Author: Yung-Kyun Noh, Ph.D.\n",
    "\n",
    "Hanyang University / Korea Institute for Advanced Study\n",
    "\n",
    "2024 Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ac312e",
   "metadata": {},
   "source": [
    "This notebook implements simple diffusion models using synthetic 2-dimensional set. \n",
    "\n",
    "The codes are based on the functions modified from the following example, \n",
    "\n",
    "https://colab.research.google.com/drive/1AZ2_BAwXrU8InE_qAE9cFZ0lsIO5a_xp?usp=sharing,\n",
    "\n",
    "which has been explained in \n",
    "\n",
    "https://medium.com/mlearning-ai/enerating-images-with-ddpms-a-pytorch-implementation-cef5a2ba8cb1.\n",
    "\n",
    "Partly, sample hands-on codes in the following NVIDIA DLI program is used.\n",
    "\n",
    "https://www.nvidia.com/en-us/training/instructor-led-workshops/generative-ai-with-diffusion-models/.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf468eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Visualization tools\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "import math\n",
    "\n",
    "# Setting reproducibility\n",
    "SEED = 0\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33bce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb27633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting device\n",
    "run_gpu = 1    # 0,1,2,3,...\n",
    "dev = 'cuda:' + str(run_gpu)\n",
    "# dev='cpu'\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(dev if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\\t\" + (f\"{torch.cuda.get_device_name(0)}\" if torch.cuda.is_available() else \"CPU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e877b8b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a6d111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_data(data_0, data_1, title_str='Data'):\n",
    "    # function for scattering data\n",
    "    \n",
    "    # create a figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Scatter data points in 2-dimensional space\n",
    "    ax.scatter(data_0[:,0], data_0[:,1], label='class 0', c='red', alpha=.3)\n",
    "    ax.scatter(data_1[:,0], data_1[:,1], label='class 1', marker='^', c='blue', alpha=.3)\n",
    "    # set a title and labels\n",
    "    ax.set_title(title_str)\n",
    "    ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35270031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate two Gaussians (class 1 & class 2)\n",
    "dim = 2\n",
    "datanum_0 = 200\n",
    "datanum_1 = 200\n",
    "mean_0 = np.array([-.1, .1])\n",
    "mean_1 = np.array([.1, -.1])\n",
    "cov_0 = np.array([[.1,.02],[.02,.1]])\n",
    "cov_1 = np.array([[.1,.09],[.09,.1]])\n",
    "# float32\n",
    "L = torch.linalg.cholesky(torch.from_numpy(cov_0).to(dev)).to(torch.float32)\n",
    "data_0 = torch.matmul(torch.randn(datanum_0, dim, device=dev, dtype=torch.float32), L.T) \\\n",
    "        + torch.from_numpy(mean_0).to(torch.float32).to(dev)\n",
    "L = torch.linalg.cholesky(torch.from_numpy(cov_1).to(dev)).to(torch.float32)\n",
    "data_1 = torch.matmul(torch.randn(datanum_1, dim, device=dev, dtype=torch.float32), L.T) \\\n",
    "        + torch.from_numpy(mean_1).to(torch.float32).to(dev)\n",
    "\n",
    "# data_0 = np.random.multivariate_normal(mean_0, cov_0, datanum_0)\n",
    "# data_1 = np.random.multivariate_normal(mean_1, cov_1, datanum_1)\n",
    "\n",
    "n_classes = 2\n",
    "data = torch.cat([data_0, data_1])\n",
    "datanums = [len(data_0), len(data_1)]\n",
    "labels = torch.cat([torch.zeros(datanums[0]), torch.ones(datanums[1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003e4be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_data(data_0.cpu(), data_1.cpu(), title_str='Data')\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(-3, 3)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff23c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDPM class\n",
    "class MyDDPM(nn.Module):\n",
    "    def __init__(self, network, n_steps=200, min_beta=10 ** -4, max_beta=0.02, device=None):\n",
    "        super(MyDDPM, self).__init__()\n",
    "        self.n_steps = n_steps\n",
    "        self.device = device\n",
    "        self.network = network.to(device)\n",
    "        self.betas = torch.linspace(min_beta, max_beta, n_steps).to(\n",
    "            device)  # Number of steps is typically in the order of thousands\n",
    "        self.alphas = 1 - self.betas\n",
    "        self.alpha_bars = torch.tensor([torch.prod(self.alphas[:i + 1]) for i in range(len(self.alphas))]).to(device)\n",
    "\n",
    "    def forward(self, x0, t, eta=None):\n",
    "        # Make input image more noisy (we can directly skip to the desired step)\n",
    "        n, c, h, w = x0.shape\n",
    "        a_bar = self.alpha_bars[t]\n",
    "\n",
    "        if eta is None:\n",
    "            eta = torch.randn(n, c, h, w).to(self.device)\n",
    "\n",
    "        noisy = a_bar.sqrt().reshape(n, 1, 1, 1) * x0 + (1 - a_bar).sqrt().reshape(n, 1, 1, 1) * eta\n",
    "        return noisy\n",
    "\n",
    "    def backward(self, x, t):\n",
    "        # Run each image through the network for each timestep t in the vector t.\n",
    "        # The network returns its estimation of the noise that was added.\n",
    "        return self.network(x, t)\n",
    "    \n",
    "    def backward_cfg(self, x, t, c, c_mask):   # Classifier-free guidance\n",
    "        return self.network(x, t, c, c_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d2f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diffuse data\n",
    "T_col = 8\n",
    "T_row = 10\n",
    "T = T_col*T_row\n",
    "B_start = 0.0001\n",
    "B_end = 0.02\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18ccf14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33f3dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbedBlock(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim):\n",
    "        super(EmbedBlock, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        layers = [\n",
    "            nn.Linear(input_dim, emb_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(emb_dim, emb_dim),\n",
    "#             nn.Unflatten(1, (emb_dim, 1, 1)),\n",
    "            nn.Unflatten(1, (emb_dim,))  # Noh, corrected\n",
    "        ]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_dim)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae07f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPositionEmbedBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710896bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class epsilon_diffuse(nn.Module): # all the dependencies from torch will be given to this class [parent class] # nn.Module contains all the building block of neural networks:\n",
    "  def __init__(self, input_dim, output_dim, T, ns_layer=[10,5,3], t_embed_dim=8, c_embed_dim=3):\n",
    "    super(epsilon_diffuse,self).__init__()  # building connection with parent and child classes\n",
    "    self.T = T\n",
    "    self.fc1=nn.Linear(input_dim, ns_layer[0], bias=True)       # hidden layer 1\n",
    "    self.fc2=nn.Linear(ns_layer[0], ns_layer[1], bias=True)     # hidden layer 2\n",
    "    self.fc3=nn.Linear(ns_layer[1], ns_layer[2], bias=True)     # hidden layer 3\n",
    "    self.fc4=nn.Linear(ns_layer[2], output_dim)          # last layer\n",
    "\n",
    "    self.sinusoidaltime = SinusoidalPositionEmbedBlock(t_embed_dim)\n",
    "    self.t_emb1 = EmbedBlock(t_embed_dim, ns_layer[0])\n",
    "    self.t_emb2 = EmbedBlock(t_embed_dim, ns_layer[1])\n",
    "    self.c_embed1 = EmbedBlock(c_embed_dim, ns_layer[0])  # dim n_classes -> dim layer\n",
    "    self.c_embed2 = EmbedBlock(c_embed_dim, ns_layer[1])  # dim n_classes -> dim layer\n",
    "\n",
    "  def forward(self, x, t, c, c_mask):\n",
    "    t = t.float() / self.T  # Convert from [0, T] to [0, 1]\n",
    "    t = self.sinusoidaltime(t)\n",
    "    t_emb1 = self.t_emb1(t)\n",
    "    t_emb2 = self.t_emb2(t)\n",
    "\n",
    "    c = c*c_mask\n",
    "    c_emb1 = self.c_embed1(c)\n",
    "    c_emb2 = self.c_embed2(c)\n",
    "\n",
    "    out=torch.relu(self.fc1(x))              # input * weights + bias for layer 1\n",
    "    out=torch.relu(self.fc2(c_emb1*out + t_emb1))            # input * weights + bias for layer 2\n",
    "    out=torch.relu(self.fc3(c_emb2*out + t_emb2))            # input * weights + bias for layer 3\n",
    "    out=self.fc4(out)                        # input * weights + bias for last layer\n",
    "    return out                               # final outcome\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50b1d4c",
   "metadata": {},
   "source": [
    "### Initiating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7306bcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDPM class\n",
    "class MyDDPM(nn.Module):\n",
    "    def __init__(self, network, n_steps=200, min_beta=10 ** -4, max_beta=0.02, device=None):\n",
    "        super(MyDDPM, self).__init__()\n",
    "        self.n_steps = n_steps\n",
    "        self.device = device\n",
    "        self.network = network.to(device)\n",
    "        self.betas = torch.linspace(min_beta, max_beta, n_steps).to(\n",
    "            device)  # Number of steps is typically in the order of thousands\n",
    "        self.alphas = 1 - self.betas\n",
    "        self.alpha_bars = torch.tensor([torch.prod(self.alphas[:i + 1]) for i in range(len(self.alphas))]).to(device)\n",
    "\n",
    "    def forward(self, x0, t, eta=None):\n",
    "        # Make input image more noisy (we can directly skip to the desired step)\n",
    "        n, d = x0.shape\n",
    "        a_bar = self.alpha_bars[t]\n",
    "\n",
    "        if eta is None:\n",
    "            eta = torch.randn(n, d).to(self.device)\n",
    "\n",
    "        noisy = a_bar.sqrt().reshape(n, 1) * x0 + (1 - a_bar).sqrt().reshape(n, 1) * eta\n",
    "        return noisy\n",
    "\n",
    "    def backward(self, x, t):\n",
    "        # Run each image through the network for each timestep t in the vector t.\n",
    "        # The network returns its estimation of the noise that was added.\n",
    "        return self.network(x, t)\n",
    "    \n",
    "    def backward_cfg(self, x, t, c, c_mask):   # Classifier-free guidance\n",
    "        return self.network(x, t, c, c_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f351d921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model\n",
    "n_steps, min_beta, max_beta = 1000, 10 ** -4, 0.02  # Originally used by the authors\n",
    "input_dim=2\n",
    "output_dim=2\n",
    "\n",
    "ddpm = MyDDPM(epsilon_diffuse(input_dim, output_dim, T, ns_layer=[50,50,3], c_embed_dim=2), \\\n",
    "              n_steps=n_steps, min_beta=min_beta, max_beta=max_beta, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a441e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([p.numel() for p in ddpm.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea876af",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f24b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_mask(c, drop_prob, n_classes=2, device='cpu'):\n",
    "    c_hot = F.one_hot(c.to(torch.int64), num_classes=n_classes).to(device)\n",
    "    c_mask = torch.bernoulli(torch.ones_like(c_hot).float() - drop_prob).to(device)\n",
    "    return c_hot, c_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fd6308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop_cfg(ddpm, data, labels, n_epochs, optim, device, n_classes=10, c_drop_prob=0.1, display=False, store_path=\"ddpm_model.pt\"):\n",
    "    mse = nn.MSELoss()\n",
    "    best_loss = float(\"inf\")\n",
    "    n_steps = ddpm.n_steps\n",
    "\n",
    "    for epoch in tqdm(range(n_epochs), desc=f\"Training progress\", colour=\"#00ff00\"):\n",
    "        epoch_loss = 0.0\n",
    "        x0 = data\n",
    "        n = len(x0)\n",
    "        c_hot, c_mask = get_context_mask(labels, c_drop_prob, n_classes=n_classes, device=device)  # New\n",
    "\n",
    "        # Picking some noise for each of the images in the batch, a timestep and the respective alpha_bars\n",
    "        eta = torch.randn_like(x0).to(device)\n",
    "        t = torch.randint(0, n_steps, (n,)).to(device)\n",
    "\n",
    "        # Computing the noisy image based on x0 and the time-step (forward process)\n",
    "        noisy_imgs = ddpm(x0, t, eta)\n",
    "\n",
    "        # Getting model estimation of noise based on the images and the time-step\n",
    "        eta_theta = ddpm.backward_cfg(noisy_imgs, t.reshape(n, -1), c_hot, c_mask)\n",
    "\n",
    "        # Optimizing the MSE between the noise plugged and the predicted noise\n",
    "        loss = mse(eta_theta, eta)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        epoch_loss += loss.item() * len(x0) / len(data)\n",
    "\n",
    "        # Display images generated at this epoch\n",
    "        if display:\n",
    "            show_images(generate_new_images(ddpm, device=device), f\"Images generated at epoch {epoch + 1}\")\n",
    "\n",
    "        log_string = f\"Loss at epoch {epoch + 1}: {epoch_loss:.3f}\"\n",
    "\n",
    "        # Storing the model\n",
    "        if best_loss > epoch_loss:\n",
    "            best_loss = epoch_loss\n",
    "            torch.save(ddpm.state_dict(), store_path)\n",
    "            log_string += \" --> Best model ever (stored)\"\n",
    "\n",
    "        print(log_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51e69e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "# n_epochs = 20\n",
    "n_epochs = 1000\n",
    "lr = 0.001\n",
    "\n",
    "# Training\n",
    "store_path = \"ddpm_2d_cfg.pt\"\n",
    "training_loop_cfg(ddpm, data, labels, n_epochs, optim=Adam(ddpm.parameters(), lr), device=device, \\\n",
    "                  n_classes=n_classes, store_path=store_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e11da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the trained model\n",
    "best_model = MyDDPM(epsilon_diffuse(input_dim, output_dim, T, ns_layer=[50,50,3], c_embed_dim=2), \\\n",
    "                    n_steps=n_steps, min_beta=min_beta, max_beta=max_beta, device=device)\n",
    "store_path = \"ddpm_2d_cfg.pt\"\n",
    "best_model.load_state_dict(torch.load(store_path, map_location=device))\n",
    "best_model.eval()\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00c7ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with w\n",
    "def generate_new_data_cfg(ddpm, n_samples, labels, n_classes=2, \\\n",
    "                          device=None, frames_per_gif=100, gif_name=\"sampling.gif\", \\\n",
    "                          d=2, w_val = 0.):\n",
    "    \"\"\"Given a DDPM model, a number of samples to be generated and a device, returns some newly generated samples\"\"\"\n",
    "    frame_idxs = np.linspace(0, ddpm.n_steps, frames_per_gif).astype(np.uint)\n",
    "    frames = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if device is None:\n",
    "            device = ddpm.device\n",
    "\n",
    "        # Starting from random noise\n",
    "        x = torch.randn(n_samples, d).to(device)\n",
    "\n",
    "        for idx, t in enumerate(list(range(ddpm.n_steps))[::-1]):\n",
    "            # Estimating noise to be removed\n",
    "            time_tensor = (torch.ones(n_samples, 1) * t).to(device).long()\n",
    "            c_drop_prob = 0 \n",
    "            c_hot, c_mask = get_context_mask(labels, c_drop_prob, device=device)\n",
    "            eta_theta_keep_class = ddpm.backward_cfg(x, time_tensor, c_hot, c_mask)\n",
    "            c_mask = torch.zeros_like(c_mask) \n",
    "            eta_theta_drop_class = ddpm.backward_cfg(x, time_tensor, c_hot, c_mask)\n",
    "            eta_theta = (1 + w_val) * eta_theta_keep_class - w_val * eta_theta_drop_class\n",
    "\n",
    "            alpha_t = ddpm.alphas[t]\n",
    "            alpha_t_bar = ddpm.alpha_bars[t]\n",
    "\n",
    "            # Partially denoising the image\n",
    "            x = (1 / alpha_t.sqrt()) * (x - (1 - alpha_t) / (1 - alpha_t_bar).sqrt() * eta_theta)\n",
    "\n",
    "            if t > 0:\n",
    "                z = torch.randn(n_samples, d).to(device)\n",
    "\n",
    "                # Option 1: sigma_t squared = beta_t\n",
    "                beta_t = ddpm.betas[t]\n",
    "                sigma_t = beta_t.sqrt()\n",
    "\n",
    "                # Option 2: sigma_t squared = beta_tilda_t\n",
    "                # prev_alpha_t_bar = ddpm.alpha_bars[t-1] if t > 0 else ddpm.alphas[0]\n",
    "                # beta_tilda_t = ((1 - prev_alpha_t_bar)/(1 - alpha_t_bar)) * beta_t\n",
    "                # sigma_t = beta_tilda_t.sqrt()\n",
    "\n",
    "                # Adding some more noise like in Langevin Dynamics fashion\n",
    "                x = x + sigma_t * z\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de4d47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gen = 300\n",
    "labels = torch.cat([torch.zeros(int(n_gen/2)), torch.ones(int(n_gen/2))])\n",
    "generated = generate_new_data_cfg(\n",
    "        best_model, n_gen, labels,\n",
    "        n_classes=n_classes,\n",
    "        device=device,\n",
    "        gif_name=\"synthetic_2d_cfg.gif\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8481bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_data(generated[labels==0].cpu(), generated[labels==1].cpu(), title_str='Generated Data')\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(-3, 3)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f93ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3de00b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_val = 1.\n",
    "n_gen = 300\n",
    "labels = torch.cat([torch.zeros(int(n_gen/2)), torch.ones(int(n_gen/2))])\n",
    "generated = generate_new_data_cfg(\n",
    "        best_model, n_gen, labels,\n",
    "        n_classes=n_classes,\n",
    "        device=device,\n",
    "        gif_name=\"synthetic_2d_cfg.gif\", w_val=w_val\n",
    "    )\n",
    "\n",
    "draw_data(generated[labels==0].cpu(), generated[labels==1].cpu(), title_str='Generated Data')\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(-3, 3)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a615ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_val = 2.\n",
    "n_gen = 300\n",
    "labels = torch.cat([torch.zeros(int(n_gen/2)), torch.ones(int(n_gen/2))])\n",
    "generated = generate_new_data_cfg(\n",
    "        best_model, n_gen, labels,\n",
    "        n_classes=n_classes,\n",
    "        device=device,\n",
    "        gif_name=\"synthetic_2d_cfg.gif\", w_val=w_val\n",
    "    )\n",
    "\n",
    "draw_data(generated[labels==0].cpu(), generated[labels==1].cpu(), title_str='Generated Data')\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(-3, 3)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21615c64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
